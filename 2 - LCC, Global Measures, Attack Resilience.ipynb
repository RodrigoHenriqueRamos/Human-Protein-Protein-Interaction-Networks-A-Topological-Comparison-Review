{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3208b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import random as rd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8044255",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks={}\n",
    "networks['HINT'] = nx.read_edgelist('1 - output/HINT_Complete.edgelist',delimiter='\\t')\n",
    "networks['IntAct'] = nx.read_edgelist('1 - output/intAct_Significant.edgelist',delimiter='\\t')\n",
    "networks['Reactome'] = nx.read_edgelist('1 - output/Reactome_Significant.edgelist',delimiter='\\t')\n",
    "networks['STRING'] = nx.read_edgelist('1 - output/STRING_Significant.edgelist',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0a120",
   "metadata": {},
   "source": [
    "## Connected Components, Self Loops and LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21921157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HINT\n",
      "Top 10: [14763, 4, 3, 3, 2, 2, 2, 2, 2, 2]\n",
      "LCC 14763 (96%)\n",
      "\n",
      "IntAct\n",
      "Top 10: [13268, 5, 3, 3, 3, 3, 3, 3, 3, 2]\n",
      "LCC 13268 (99%)\n",
      "\n",
      "Reactome\n",
      "Top 10: [11873, 9, 8, 8, 6, 6, 5, 5, 5, 5]\n",
      "LCC 11873 (97%)\n",
      "\n",
      "STRING\n",
      "Top 10: [16582, 9, 5, 5, 4, 4, 4, 4, 4, 4]\n",
      "LCC 16582 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in networks:\n",
    "    #CCs Info\n",
    "    G = networks[name]\n",
    "    ccs = sorted(nx.connected_components(G),key=len,reverse=True)\n",
    "    print(name)\n",
    "    print('Top 10:',[len(cc) for cc in ccs][:10])\n",
    "    print('LCC',len(ccs[0]),'('+str(round(len(ccs[0])/len(G)*100))+'%)')\n",
    "    #UPDATE G to LCC\n",
    "    networks[name] = nx.subgraph(networks[name],ccs[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b649dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HINT 118901\n",
      "HINT 114588\n",
      "IntAct 91578\n",
      "IntAct 90446\n",
      "Reactome 228447\n",
      "Reactome 228447\n",
      "STRING 252802\n",
      "STRING 252801\n"
     ]
    }
   ],
   "source": [
    "# Remove Self Loops\n",
    "for name in networks:\n",
    "    print(name,networks[name].number_of_edges())\n",
    "    G = networks[name].copy()\n",
    "    G.remove_edges_from(\n",
    "            nx.selfloop_edges(networks[name])\n",
    "        )\n",
    "    networks[name]=G\n",
    "    print(name,networks[name].number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b74e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(96+99+97+99)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53ede51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LCC\n",
    "for name in networks:\n",
    "    G = networks[name]\n",
    "    nx.write_edgelist(G,\"2 - output\\\\\"+name+'.edgelist',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85e3ae",
   "metadata": {},
   "source": [
    "## Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0d1b619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HINT\n",
      "HPRD\n",
      "IntAct\n",
      "MINT\n",
      "Reactome\n",
      "STRING\n",
      "CPU times: total: 1h 7min 27s\n",
      "Wall time: 1h 7min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "comunities={}\n",
    "for name in networks:\n",
    "    print(name)\n",
    "    G = networks[name]\n",
    "    comunities[name]=sorted([list(com) for com in nx.community.greedy_modularity_communities(G)],key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9e90d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('2 - output/communities.pickle', 'wb')\n",
    "pickle.dump(comunities, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2f35aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del comunities\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd7a87",
   "metadata": {},
   "source": [
    "# Assortativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8aebf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageNeighborsDegree(G,node):\n",
    "    neighbors=list(nx.neighbors(G,node))\n",
    "    if(len(neighbors)==0):\n",
    "        return 0 \n",
    "    else:\n",
    "        return sum([nx.degree(G,n) for n in neighbors])/len(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2e42632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HINT\n",
      "HPRD\n",
      "IntAct\n",
      "MINT\n",
      "Reactome\n",
      "STRING\n"
     ]
    }
   ],
   "source": [
    "assortativity={}\n",
    "for name in networks:\n",
    "    print(name)\n",
    "    assortativity[name]={}\n",
    "    G = networks[name]\n",
    "    nodeWithDegreeK={}\n",
    "    #Get the nodes with degree 'k'\n",
    "    for node,k in dict(G.degree).items():\n",
    "        if k not in nodeWithDegreeK:\n",
    "            nodeWithDegreeK[k]=[node]\n",
    "        else:\n",
    "            nodeWithDegreeK[k].append(node)\n",
    "    #Get the average neighbors degree for every node with degree'k'\n",
    "    for k in nodeWithDegreeK:\n",
    "        means=0\n",
    "        for node in nodeWithDegreeK[k]:\n",
    "            means+=averageNeighborsDegree(G,node)\n",
    "        nodeWithDegreeK[k]=round(means/len(nodeWithDegreeK[k]),2)\n",
    "    assortativity[name]['distribution']=nodeWithDegreeK\n",
    "    assortativity[name]['coefficient']=nx.assortativity.degree_assortativity_coefficient(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4636427",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('2 - output/assortativity.pickle', 'wb')\n",
    "pickle.dump(assortativity, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806589a9",
   "metadata": {},
   "source": [
    "# Small World and Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a350155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HINT\n",
      "HPRD\n",
      "IntAct\n",
      "MINT\n",
      "Reactome\n",
      "STRING\n"
     ]
    }
   ],
   "source": [
    "smallWorld={}\n",
    "for name in networks:\n",
    "    print(name)\n",
    "    G = networks[name]\n",
    "    smallWorld[name]={}\n",
    "    \n",
    "    ecc=list(nx.eccentricity(G).values())\n",
    "    avgSP = round(nx.average_shortest_path_length(G),2)\n",
    "    diameter=round(max(ecc))\n",
    "\n",
    "    eccentricityProb={}\n",
    "    total = len(ecc)\n",
    "    for c in ecc:\n",
    "        if c in eccentricityProb:\n",
    "            eccentricityProb[c]+=1\n",
    "        else:\n",
    "            eccentricityProb[c]=1\n",
    "\n",
    "    for c in eccentricityProb:\n",
    "        eccentricityProb[c]=eccentricityProb[c]/total\n",
    "\n",
    "    eccentricityProb = dict(sorted(eccentricityProb.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    smallWorld[name]['avgSP']=avgSP\n",
    "    smallWorld[name]['diameter']=diameter\n",
    "    smallWorld[name]['ecc']=eccentricityProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "69cb3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('2 - output/smallWorld.pickle', 'wb')\n",
    "pickle.dump(smallWorld, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a801de",
   "metadata": {},
   "source": [
    "# Attack and Resilience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f32ef2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mr is the MatrixOfResults\n",
    "def getErroSTD(mr):\n",
    "    #Variance calculation.\n",
    "    results=[r[1] for r in mr]\n",
    "    resultsVariance=[]\n",
    "    #results is a matriz. Each line is a repetion that contains 'howMany' values (howMany is the number of removed nodes)\n",
    "    #The columns in this matriz are the values found in a point in time (f). So we can calculate the variance for each point \n",
    "    numberOfColumns = len(results[0])\n",
    "    for col in range(numberOfColumns):\n",
    "        colValues=[]\n",
    "        for line in results:\n",
    "            colValues.append(line[col])\n",
    "        resultsVariance.append(np.std(colValues))   \n",
    "    return resultsVariance\n",
    "\n",
    "def rd_impact(G_original,repeat):\n",
    "    matrizOfResults=[]\n",
    "    for _ in range(repeat):\n",
    "        G = G_original.copy()\n",
    "        Nstart = G.number_of_nodes()\n",
    "        yAxis=[1]\n",
    "        xAxis=[0]\n",
    "        listOfNode = list(G.nodes)\n",
    "        rd.shuffle(listOfNode)#Randomize the nodes\n",
    "        for i,_ in enumerate(range(len(listOfNode))):\n",
    "            G.remove_node(listOfNode[i])\n",
    "            Nactual = G.number_of_nodes()\n",
    "            CCs = nx.connected_components(G)\n",
    "            if Nactual != 0:\n",
    "                LCC = max(CCs,key=len)\n",
    "                #𝑃∞(𝑓)/𝑃∞(0)  = len(LCC)/Nstart # Because we start with a connect network, with only one connect component\n",
    "                impact = len(LCC)/Nstart\n",
    "            else:\n",
    "                impact = 0 \n",
    "            f = 1 - Nactual/Nstart\n",
    "            yAxis.append(impact)\n",
    "            xAxis.append(f)\n",
    "            \n",
    "        matrizOfResults.append([np.array(xAxis),np.array(yAxis)])\n",
    "        \n",
    "    y = np.array(matrizOfResults[0][1])\n",
    "    for ex in matrizOfResults:\n",
    "        y+=ex[1]\n",
    "    y=y/(repeat+1)    \n",
    "    \n",
    "    error=getErroSTD(matrizOfResults)\n",
    "    return matrizOfResults,error,xAxis,y\n",
    "  \n",
    "def intentional_impact(G_original,repeat):\n",
    "    matrizOfResults=[]\n",
    "    for _ in range(repeat):\n",
    "        G = G_original.copy()\n",
    "        Nstart = G.number_of_nodes()\n",
    "        yAxis=[1]\n",
    "        xAxis=[0]\n",
    "\n",
    "        #verticesOrdenados is a list of tuples (verticeName,degree)\n",
    "        verticesOrdenados = list(dict(sorted(dict(G.degree).items(), key=lambda x:x[1],reverse=True)).items())\n",
    "        #In case two or more hubs have the same degree\n",
    "        first=verticesOrdenados[0]\n",
    "        equalsToFirst=[first[0]]\n",
    "        cont=1\n",
    "        while cont<len(verticesOrdenados) and first[1] == verticesOrdenados[cont][1]:\n",
    "            equalsToFirst.append(verticesOrdenados[cont][0])\n",
    "            cont+=1\n",
    "        #randomize the list of hubs that have the same degree\n",
    "        rd.shuffle(equalsToFirst)\n",
    "        verticeToRemove=equalsToFirst[0]\n",
    "\n",
    "        for step in range(Nstart):    \n",
    "            G.remove_node(verticeToRemove)\n",
    "            Nactual = G.number_of_nodes()\n",
    "            CCs = nx.connected_components(G)\n",
    "            if Nactual != 0:\n",
    "                LCC = max(CCs,key=len)\n",
    "                #𝑃∞(𝑓)/𝑃∞(0)  = len(LCC)/Nstart # Because we start with a connect network, with only one connect component\n",
    "                impact = len(LCC)/Nstart\n",
    "            else:\n",
    "                impact = 0 \n",
    "            f = 1 - Nactual/Nstart\n",
    "            yAxis.append(impact)\n",
    "            xAxis.append(f)\n",
    "\n",
    "            #verticesOrdenados is a list of tuples (verticeName,degree)\n",
    "            verticesOrdenados = list(dict(sorted(dict(G.degree).items(), key=lambda x:x[1],reverse=True)).items())\n",
    "            #In case two or more hubs have the same degree\n",
    "            if(len(verticesOrdenados)>0):\n",
    "                first=verticesOrdenados[0]\n",
    "                equalsToFirst=[first[0]]\n",
    "                cont=1\n",
    "                while cont<len(verticesOrdenados) and first[1] == verticesOrdenados[cont][1]:\n",
    "                    equalsToFirst.append(verticesOrdenados[cont][0])\n",
    "                    cont+=1\n",
    "                #randomize the list of hubs that have the same degree\n",
    "                rd.shuffle(equalsToFirst)\n",
    "                verticeToRemove=equalsToFirst[0]\n",
    "\n",
    "\n",
    "        matrizOfResults.append([np.array(xAxis),np.array(yAxis)])\n",
    "\n",
    "    #Calculate the average of all repeat\n",
    "    y = np.array(matrizOfResults[0][1])\n",
    "    for ex in matrizOfResults:\n",
    "        y+=ex[1]\n",
    "    y=y/(repeat+1)\n",
    "    \n",
    "    #Calculate de error and plotIT\n",
    "    error=getErroSTD(matrizOfResults)\n",
    "    \n",
    "    return matrizOfResults,error,xAxis,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eecca2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HINT\n",
      "HINT Random\n",
      "HINT Hubs\n",
      "HPRD\n",
      "HPRD Random\n",
      "HPRD Hubs\n",
      "IntAct\n",
      "IntAct Random\n",
      "IntAct Hubs\n",
      "MINT\n",
      "MINT Random\n",
      "MINT Hubs\n",
      "Reactome\n",
      "Reactome Random\n",
      "Reactome Hubs\n",
      "STRING\n",
      "STRING Random\n",
      "STRING Hubs\n",
      "CPU times: total: 12h 59min 15s\n",
      "Wall time: 12h 59min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "matrizOfImpacts={}\n",
    "numberAttacksRandom=30\n",
    "numberAttacksHub=10\n",
    "\n",
    "for name in networks:\n",
    "    print(name)\n",
    "    G = networks[name]\n",
    "    LCC = nx.subgraph(G,max(nx.connected_components(G)))\n",
    "    matrizOfImpacts[name]={}    \n",
    "    matrizOfImpacts[name]['Random']=rd_impact(LCC,numberAttacksRandom)\n",
    "    print(name+' Random')\n",
    "    matrizOfImpacts[name]['Hubs']=intentional_impact(LCC,numberAttacksHub)\n",
    "    print(name+' Hubs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f92fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('2 - output/attackResilience.pickle', 'wb')\n",
    "pickle.dump(matrizOfImpacts, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
